{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "TRAINING_ITERATIONS = 100000\n",
    "\n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "\n",
    "VALIDATION_SIZE =0\n",
    "IMAGE_TO_DISPLAY = 10\n",
    "\n",
    "IS_TRAIN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('mnist_train.csv')\n",
    "\n",
    "#print('data({0[0]},{0[1]})'.format(data.shape))\n",
    "#print(data.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images(59999,784)\n"
     ]
    }
   ],
   "source": [
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "images = np.multiply(images ,1.0/255.0)\n",
    "print('images({0[0]},{0[1]})'.format(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " image_size  => 784\n",
      "image_width = >28.0\n",
      " image_height =>28.0\n"
     ]
    }
   ],
   "source": [
    "image_size = images.shape[1]\n",
    "print(' image_size  => {0}'.format(image_size))\n",
    "\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size).astype(np.uint8))\n",
    "\n",
    "print('image_width = >{0}\\n image_height =>{1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+CGU+CGU+CGU+CHUL8gkrqK+OIf4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd335be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display(img):\n",
    "    one_image = img.reshape(28,28)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image,cmap =cm.binary)\n",
    "\n",
    "display(images[IMAGE_TO_DISPLAY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_flat(59999)\n",
      "labels_flat[10] =>5\n"
     ]
    }
   ],
   "source": [
    "labels_flat = data.iloc[:,0].values.ravel()\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "print('labels_flat[{0}] =>{1}'.format(IMAGE_TO_DISPLAY,labels_flat[IMAGE_TO_DISPLAY]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "print(labels_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 10)\n",
      "labels[10] => [0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def dense_to_one_hot(labels_dense,num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels,num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] =1\n",
    "    return labels_one_hot\n",
    "\n",
    "labels = dense_to_one_hot(labels_flat,labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "print(labels.shape)\n",
    "print('labels[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels[IMAGE_TO_DISPLAY]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 784)\n",
      "(0, 784)\n"
     ]
    }
   ],
   "source": [
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]\n",
    "\n",
    "print(train_images.shape)\n",
    "print(validation_images.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1 ,shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    \n",
    "    return tf.nn.conv2d(x,W,strides = [1,1,1,1],padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize = [1,2,2,1],strides = [1,2,2,1],padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape = [None,image_size])\n",
    "y_ = tf.placeholder(tf.float32,shape = [None , labels_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first conv  layer\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "image = tf.reshape(x,[-1,28,28,1])\n",
    "h_conv1 = tf.nn.relu(conv2d(image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#second conv layer\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7*7*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024,labels_count])\n",
    "b_fc2 = bias_variable([labels_count])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy =  -tf.reduce_sum(y_ * tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))  #argmax（y，1-） 返回列中最大值所在的位置\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))   #求平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = tf.argmax(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]\n",
    "\n",
    "def next_batch(batch_size):\n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > num_examples:\n",
    "        epochs_completed += 1\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        \n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <=num_examples\n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return train_images[start:end] , train_labels[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ckpt/mnist.ckpt\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAA6NJREFUeJzt3UFuIkEUBUGXxf2vXD4BNALTVXRG\nbGekQR6n/uI1MOacP0DP7+oXAKwhfogSP0SJH6LED1HihyjxQ5T4IUr8EHU7+d/zOCF83njmL7n8\nECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LE\nD1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHqLO/ojtpjKe+MXmJOX1repXLD1HihyjxQ5T4IUr8\nECV+iBI/RNn5/8HOO/6RnV+7ZxA+y+WHKPFDlPghSvwQJX6IEj9EiR+ixslbanK43XlL/2aeA7jr\nqV84lx+ixA9R4oco8UOU+CFK/BBl6ru48swYngJNfcB94oco8UOU+CFK/BAlfogSP0T56O6L23nr\nLj+DsAOXH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R\n4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQ\nJX6IEj9EiR+ixA9R4oco8UOU+CFK/BB1W/0CuLYxxuqXwB0uP0SJH6LED1HihyjxQ5T4IUr8EGXn\n56Gdd/o55+qX8NVcfogSP0SJH6LED1HihyjxQ5T4IcrOf3E77/Ss5fJDlPghSvwQJX6IEj9EiR+i\nTH0bMMe95p2fm7cDu/yQJX6IEj9EiR+ixA9R4oco8UOUnf8Edvz9HP2fFJ4DcPkhSvwQJX6IEj9E\niR+ixA9R4ocoO/8JjjZjzwGwgssPUeKHKPFDlPghSvwQJX6IEj9E2fk3UHjv+Cd4PuI9Lj9EiR+i\nxA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPgh\nykd3sy0fzf1ZLj9EiR+ixA9R4oco8UOU+CFK/BBl59+APZsVXH6IEj9EiR+ixA9R4oco8UOU+CHK\nzn8COz47cvkhSvwQJX6IEj9EiR+ixA9Rpr4TzDkf/rkp8DVHP1cec/khSvwQJX6IEj9EiR+ixA9R\n4ocoO/8G7NWs4PJDlPghSvwQJX6IEj9EiR+ixA9RZ+/83rgOm3D5IUr8ECV+iBI/RIkfosQPUeKH\nKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6g/PnI1Ihk7LgcA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4c150358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "saver = tf.train.Saver() \n",
    "checkpoint_dir = ''\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_accuracies = []\n",
    "    validation_accuracies = []\n",
    "    x_range = []\n",
    "    display_step = 1\n",
    "    \n",
    "    if IS_TRAIN:\n",
    "        for i in range(TRAINING_ITERATIONS):\n",
    "            batch_xs , batch_ys  = next_batch(BATCH_SIZE)\n",
    "            if i%display_step ==0 or (i+1) == TRAINING_ITERATIONS:\n",
    "                train_accuracy = accuracy.eval(feed_dict = {x:batch_xs,y_:batch_ys,keep_prob:1.0})\n",
    "                if(VALIDATION_SIZE):\n",
    "                    validation_accuracy = accuracy.eval(feed_dict = {x: validation_images[:VALIDATION_SIZE],\n",
    "                                                                     y_:validation_labels[:VALIDATION_SIZE],\n",
    "                                                                     keep_prob:1.0})\n",
    "                    print('training_accuracy/validation_accuracy => %.2f/%.2f for step %d'%(train_accuracy,validation_accuracy,i))\n",
    "                    validation_accuracies.append(validation_accuracy)\n",
    "                else:\n",
    "                    print(' training_accuracy => %4f for step %d'%(train_accuracy ,i))\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                print(' mean_training_accuracy => %4f '%(tf.reduce_mean(tf.cast(train_accuracies,tf.float32)).eval()))\n",
    "                x_range.append(i)\n",
    "                if i%(display_step *10) == 0 and i:\n",
    "                    display_step *= 10\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y_:batch_ys,keep_prob:DROPOUT})\n",
    "        saver.save(sess,'ckpt/mnist.ckpt')\n",
    "        \n",
    "        plt.plot(x_range,train_accuracies,'-b',label = 'Training')\n",
    "        plt.legend(loc = 'lower right',frameon = False)\n",
    "        plt.ylim(ymax = 1.1,ymin = 0.8)\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('step')\n",
    "        plt.show()\n",
    "    else:\n",
    "        \n",
    "        model_file=tf.train.latest_checkpoint('ckpt/')\n",
    "        saver.restore(sess,model_file)\n",
    "        mnist_img = Image.open(\"3.bmp\")\n",
    "        input = (1- np.asarray(mnist_img,dtype=np.uint8)).reshape(1,784)\n",
    "        result = predict.eval(feed_dict = {x: input,keep_prob:1.0})\n",
    "        print(result)\n",
    "        display(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
